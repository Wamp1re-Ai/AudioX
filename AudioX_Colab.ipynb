{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üéß AudioX: Diffusion Transformer for Anything-to-Audio Generation\n",
    "\n",
    "[![arXiv](https://img.shields.io/badge/arXiv-2503.10522-brightgreen.svg?style=flat-square)](https://arxiv.org/abs/2503.10522)\n",
    "[![Project Page](https://img.shields.io/badge/GitHub.io-Project-blue?logo=Github&style=flat-square)](https://zeyuet.github.io/AudioX/)\n",
    "[![ü§ó Model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Model-blue)](https://huggingface.co/HKUSTAudio/AudioX)\n",
    "\n",
    "**This notebook provides a Google Colab interface for AudioX, supporting:**\n",
    "- üìù Text-to-Audio Generation\n",
    "- üé¨ Video-to-Audio Generation  \n",
    "- üéµ Video-to-Music Generation\n",
    "- üé∂ Text-to-Music Generation\n",
    "\n",
    "**Instructions:**\n",
    "1. Run all cells in order\n",
    "2. Wait for the Gradio interface to load\n",
    "3. Use the public URL to access the demo\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## üîß Setup and Installation\n",
    "\n",
    "Choose one of the following setup options:\n",
    "\n",
    "**Option A**: Automated setup (recommended) - Run the next cell\n",
    "**Option B**: Manual setup - Skip to the cell after that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "automated_setup"
   },
   "outputs": [],
   "source": [
    "# OPTION A: Automated Setup (Recommended)\n",
    "# This cell handles everything automatically\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Check if we're in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"üöÄ Running in Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"üíª Running locally\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    try:\n",
    "        # Check if AudioX directory already exists\n",
    "        if not Path('AudioX').exists():\n",
    "            print(\"üì• Cloning AudioX repository...\")\n",
    "            !git clone https://github.com/Wamp1re-Ai/AudioX.git\n",
    "        else:\n",
    "            print(\"üìÅ AudioX directory already exists\")\n",
    "        \n",
    "        # Change to AudioX directory\n",
    "        %cd AudioX\n",
    "        print(f\"üìÅ Changed to directory: {Path.cwd()}\")\n",
    "        \n",
    "        # Install system dependencies\n",
    "        print(\"üì¶ Installing system dependencies...\")\n",
    "        !apt-get update -qq\n",
    "        !apt-get install -y ffmpeg libsndfile1 git-lfs\n",
    "        \n",
    "        # Install Python dependencies with better error handling\n",
    "        print(\"üêç Installing Python dependencies...\")\n",
    "        \n",
    "        # Install PyTorch (use Colab's version)\n",
    "        !pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "        \n",
    "        # Install essential AudioX dependencies\n",
    "        !pip install -q gradio>=4.40.0 aeiou einops safetensors transformers huggingface_hub\n",
    "        \n",
    "        # Install AudioX package\n",
    "        !pip install -q -e .\n",
    "        \n",
    "        # Create model directory\n",
    "        !mkdir -p model\n",
    "        \n",
    "        print(\"‚úÖ Automated setup complete!\")\n",
    "        print(\"üéõÔ∏è You can now skip to the 'Launch Gradio Interface' section\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Automated setup encountered issues: {e}\")\n",
    "        print(\"üîÑ Please try the manual setup option below\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  Please use manual setup for local environments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "manual_setup"
   },
   "source": [
    "## üîß Manual Setup (Option B)\n",
    "\n",
    "Use this if the automated setup fails or you prefer manual control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "# Check if we're in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"üöÄ Running in Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"üíª Running locally\")\n",
    "\n",
    "# Install system dependencies\n",
    "if IN_COLAB:\n",
    "    !apt-get update -qq\n",
    "    !apt-get install -y ffmpeg libsndfile1 git-lfs\n",
    "    \n",
    "    # Clone the repository (use the correct repo URL)\n",
    "    !git clone https://github.com/Wamp1re-Ai/AudioX.git\n",
    "    %cd AudioX\n",
    "    \n",
    "    # Install Python dependencies with better compatibility\n",
    "    !pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "    \n",
    "    # Install essential dependencies first\n",
    "    !pip install -q gradio>=4.40.0 aeiou einops safetensors transformers huggingface_hub\n",
    "    \n",
    "    # Install AudioX package\n",
    "    !pip install -q -e .\n",
    "    \n",
    "    print(\"‚úÖ Installation complete!\")\n",
    "    print(\"‚ö†Ô∏è  Note: Some dependency warnings are normal in Colab\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  Please ensure you have installed the dependencies locally\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_download"
   },
   "source": [
    "## üì• Download Pre-trained Models\n",
    "\n",
    "Download the AudioX model checkpoints from Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_models"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create model directory\n",
    "os.makedirs('model', exist_ok=True)\n",
    "\n",
    "# Download model files\n",
    "model_files = {\n",
    "    'model.ckpt': 'https://huggingface.co/HKUSTAudio/AudioX/resolve/main/model.ckpt',\n",
    "    'config.json': 'https://huggingface.co/HKUSTAudio/AudioX/resolve/main/config.json'\n",
    "}\n",
    "\n",
    "def download_file(url, filename):\n",
    "    \"\"\"Download file with progress bar\"\"\"\n",
    "    def progress_hook(block_num, block_size, total_size):\n",
    "        downloaded = block_num * block_size\n",
    "        if total_size > 0:\n",
    "            percent = min(100, downloaded * 100 / total_size)\n",
    "            print(f\"\\r{filename}: {percent:.1f}% ({downloaded//1024//1024}MB/{total_size//1024//1024}MB)\", end=\"\")\n",
    "    \n",
    "    if not os.path.exists(f'model/{filename}'):\n",
    "        print(f\"üì• Downloading {filename}...\")\n",
    "        urllib.request.urlretrieve(url, f'model/{filename}', progress_hook)\n",
    "        print(f\"\\n‚úÖ {filename} downloaded successfully!\")\n",
    "    else:\n",
    "        print(f\"‚úÖ {filename} already exists, skipping download.\")\n",
    "\n",
    "# Download all model files\n",
    "for filename, url in model_files.items():\n",
    "    download_file(url, filename)\n",
    "\n",
    "print(\"\\nüéâ All models downloaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "colab_setup"
   },
   "source": [
    "## ‚öôÔ∏è Colab-Specific Setup\n",
    "\n",
    "Configure the environment for optimal performance in Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "colab_config"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import platform\n",
    "import gc\n",
    "import os\n",
    "\n",
    "# Set environment variables for optimal performance\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['TMPDIR'] = './tmp'\n",
    "os.makedirs('./tmp', exist_ok=True)\n",
    "os.makedirs('./demo_result', exist_ok=True)\n",
    "\n",
    "# Check GPU availability\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"üéÆ GPU: {gpu_name} ({gpu_memory:.1f}GB)\")\n",
    "    \n",
    "    # Clear GPU cache\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"üíª Using CPU (GPU not available)\")\n",
    "\n",
    "print(f\"üîß Device: {device}\")\n",
    "print(f\"üêç Python: {platform.python_version()}\")\n",
    "print(f\"üî• PyTorch: {torch.__version__}\")\n",
    "\n",
    "# Memory management for Colab\n",
    "def clear_memory():\n",
    "    \"\"\"Clear GPU and system memory\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "print(\"‚úÖ Colab environment configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gradio_interface"
   },
   "source": [
    "## üéõÔ∏è Launch Gradio Interface\n",
    "\n",
    "Start the interactive AudioX demo with Gradio. The interface will be accessible via a public URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "launch_gradio",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Ensure we're in the right directory and can import modules\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Check current directory\n",
    "current_dir = Path.cwd()\n",
    "print(f\"üìÅ Current directory: {current_dir}\")\n",
    "\n",
    "# If we're not in AudioX directory, try to find it\n",
    "if not (current_dir / 'stable_audio_tools').exists():\n",
    "    if (current_dir / 'AudioX').exists():\n",
    "        os.chdir('AudioX')\n",
    "        print(\"üìÅ Changed to AudioX directory\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  AudioX directory not found. Please run the setup cells first.\")\n",
    "\n",
    "# Add current directory to Python path\n",
    "if str(Path.cwd()) not in sys.path:\n",
    "    sys.path.insert(0, str(Path.cwd()))\n",
    "    print(\"üîß Added current directory to Python path\")\n",
    "\n",
    "# Option 1: Try to use the optimized Colab interface\n",
    "interface_launched = False\n",
    "\n",
    "try:\n",
    "    from colab_gradio_interface import launch_colab_demo\n",
    "    \n",
    "    print(\"üéõÔ∏è Launching optimized Colab interface...\")\n",
    "    interface = launch_colab_demo(\n",
    "        model_config_path='./model/config.json',\n",
    "        ckpt_path='./model/model.ckpt',\n",
    "        share=True,\n",
    "        debug=False\n",
    "    )\n",
    "    interface_launched = True\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è  Colab interface not found: {e}\")\n",
    "    print(\"üîÑ Falling back to standard interface...\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Error with Colab interface: {e}\")\n",
    "    print(\"üîÑ Falling back to standard interface...\")\n",
    "\n",
    "# Option 2: Fallback to standard interface\n",
    "if not interface_launched:\n",
    "    try:\n",
    "        from stable_audio_tools.interface.gradio import create_ui\n",
    "        import gradio as gr\n",
    "        \n",
    "        # Create the interface\n",
    "        print(\"üéõÔ∏è Creating standard Gradio interface...\")\n",
    "        interface = create_ui(\n",
    "            model_config_path='./model/config.json',\n",
    "            ckpt_path='./model/model.ckpt',\n",
    "            model_half=False  # Set to True if you have memory issues\n",
    "        )\n",
    "        \n",
    "        # Configure for Colab\n",
    "        interface.queue(max_size=10)  # Limit queue size for Colab\n",
    "        \n",
    "        # Launch with public sharing enabled\n",
    "        print(\"üöÄ Launching AudioX Demo...\")\n",
    "        print(\"üì± The interface will be available at the public URL below\")\n",
    "        print(\"‚è±Ô∏è  Please wait for the model to load (this may take a few minutes)\")\n",
    "        \n",
    "        # Launch the interface\n",
    "        interface.launch(\n",
    "            share=True,  # Enable public sharing\n",
    "            debug=False,\n",
    "            server_name=\"0.0.0.0\",\n",
    "            server_port=7860,\n",
    "            show_error=True,\n",
    "            quiet=False\n",
    "        )\n",
    "        interface_launched = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error launching interface: {e}\")\n",
    "        print(\"\\nüîß Troubleshooting steps:\")\n",
    "        print(\"1. Make sure you ran all setup cells successfully\")\n",
    "        print(\"2. Check that model files exist in ./model/ directory\")\n",
    "        print(\"3. Try restarting the runtime and running cells again\")\n",
    "        print(\"4. Check the troubleshooting section below\")\n",
    "\n",
    "if interface_launched:\n",
    "    print(\"\\nüéâ AudioX is now running!\")\n",
    "    print(\"üîó Use the public URL above to access the demo\")\n",
    "    print(\"üí° Tip: Bookmark the URL to share with others\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Failed to launch interface. Please check the errors above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usage_guide"
   },
   "source": [
    "## üìñ Usage Guide\n",
    "\n",
    "### üéØ Available Tasks:\n",
    "\n",
    "1. **üìù Text-to-Audio**: Enter a text description to generate corresponding audio\n",
    "   - Example: \"Typing on a keyboard\", \"Ocean waves crashing\"\n",
    "\n",
    "2. **üé∂ Text-to-Music**: Generate music from text descriptions\n",
    "   - Example: \"An orchestral music piece for a fantasy world\"\n",
    "\n",
    "3. **üé¨ Video-to-Audio**: Upload a video file to generate matching audio\n",
    "   - Supports common video formats (MP4, AVI, MOV)\n",
    "\n",
    "4. **üéµ Video-to-Music**: Generate background music for videos\n",
    "   - Use prompt: \"Generate music for the video\"\n",
    "\n",
    "### ‚öôÔ∏è Parameters:\n",
    "\n",
    "- **Steps**: Number of diffusion steps (higher = better quality, slower)\n",
    "- **CFG Scale**: Classifier-free guidance scale (higher = more prompt adherence)\n",
    "- **Seed**: Random seed for reproducible results (-1 for random)\n",
    "- **Sampler Type**: Different sampling algorithms\n",
    "\n",
    "### üí° Tips:\n",
    "\n",
    "- Start with default parameters for best results\n",
    "- Use descriptive prompts for better audio generation\n",
    "- Video files should be under 100MB for optimal performance\n",
    "- Generation typically takes 1-3 minutes depending on settings\n",
    "\n",
    "---\n",
    "\n",
    "**üîó Links:**\n",
    "- [AudioX Paper](https://arxiv.org/abs/2503.10522)\n",
    "- [Project Page](https://zeyuet.github.io/AudioX/)\n",
    "- [GitHub Repository](https://github.com/ZeyueT/AudioX)\n",
    "- [Hugging Face Model](https://huggingface.co/HKUSTAudio/AudioX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "troubleshooting"
   },
   "source": [
    "## üîß Troubleshooting\n",
    "\n",
    "If you encounter issues, try running this cell to clear memory and restart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "troubleshoot"
   },
   "outputs": [],
   "source": [
    "# Clear memory and restart if needed\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# Clear GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"üßπ GPU memory cleared. Available: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB\")\n",
    "\n",
    "# Clear system memory\n",
    "gc.collect()\n",
    "print(\"üßπ System memory cleared\")\n",
    "\n",
    "# Check if model is loaded\n",
    "try:\n",
    "    from stable_audio_tools.interface.gradio import current_model\n",
    "    if current_model is not None:\n",
    "        print(\"‚úÖ Model is loaded and ready\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Model not loaded. Please run the Gradio interface cell again.\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è  Please run all cells in order.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
